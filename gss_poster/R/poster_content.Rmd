---
title: "GSS Poster Presentation"
author: "Kathleen E. Wendt, Siqi Zhang, & Mallory J. Feldman"
date: "10/23/2019"
output: pdf_document
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='figs/',
                      warning=FALSE, message=FALSE)
```

# Introduction

- Contemporary perspectives on the embodied mind have motivated increasing interest in psychophysiological processes and their measurement
- **[POSSIBLY INCLUDE RPLOS TEXT QUERY PLOT HERE]. Can `source()` script to bring in rplos info.
- While there has been significant theoretical and technological innovation within this domain, the field still lacks sophisticated tools for managing the quantity and qualia of data produced by physiological measures. 
- We begin to address this need, by introducing a novel pipeline for wrangling, analyzing, and visualizing peripheral physiological data.
- This pipeline is implemented in R, and capitalizes on larger discourses surrounding open science and reproducibility.

## The Problem

- Collecting and cleaning physiological data requires multiple software which are versioned and expensive.
- Using these software, the typical psychophysiology study produces several output files per-subject **[SEE DIAGRAM]
- These output files vary in their formatting and require extensive data wrangling (e.g., cleaning, exclusions, compilation, alignment) **[NOT SURE THESE EXAMPLES ARE BEST]
- When conducted via copy-and-paste (e.g., in excel) these processes introduce several researchers degrees of freedom and opportunities for error 
- Error-ridden data produces error-driven inferences 
- Because there is no standardized pipeline for data wrangling, analysis, and visualization, data is difficult to share (both internally and externally) and results are difficult to reproduce.

**[MAYBE SOMEWHERE WRITE "The Solution" or something]

## Computational reproducibility

- R ecosystem
- Rise of data science, open science, and open source software development (e.g., Unconferences)
- Tidyverse principles
- Our answer: `psyphr` - R package suite (currently supporting recent versions of MindWare Technologies workbooks)

# Load Packages

```{r packages}
# devtools::install_github("psyphr-dev/psyphr.read")
library(psyphr.read)
library(tidyverse)
library(readxl)
```

# Example data

Would it be better to take snapshots of the file directory structure and even the Excel workbook? I am trying to think about the best way to show that these data are disorganized, messy, and in need of `psyphr` tools. I don't think it would be particularly useful to include all the code required to "wrangle" one Excel workbook.

```{r xlsx_preview}
readxl::read_xlsx("../data/Pilot1/Pilot_Sub1_ECG_Baseline.xlsx", sheet = 1) %>%
  tibble::glimpse()
```

## Create lists of file names

```{r file_list1}
pilot1_files <- list.files("../data/Pilot1",
                           pattern = ".xlsx",
                           full.names = TRUE)
pilot1_files
```

```{r file_list2}
pilot2_files <- list.files("../data/Pilot2",
                           pattern = ".xlsx",
                           full.names = TRUE)
pilot2_files
```

## Use `psyphr.read::MW()` to read data 

```{r read_file1}
pilot1_list <- purrr::map(pilot1_files, psyphr.read::MW)
```

```{r read_file2}
pilot2_list <- purrr::map(pilot2_files, psyphr.read::MW)
```

## Transform


